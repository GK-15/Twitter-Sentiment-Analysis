{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "Sentiment_Analysis_for_Twitter_tweets.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89ff3389",
        "outputId": "52a050b2-6d80-4f27-fb41-69d7ce415b20"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "# import geopandas as gp\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem.porter import *\n",
        "stemmer = PorterStemmer()\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "import nltk\n",
        "nltk.download('movie_reviews')\n",
        "nltk.download('punkt')\n",
        "from textblob import TextBlob\n",
        "from textblob import Blobber\n",
        "from textblob.sentiments import NaiveBayesAnalyzer"
      ],
      "id": "89ff3389",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18d62e2c"
      },
      "source": [
        "tweets = pd.read_csv('/content/Charities_tweets.csv')"
      ],
      "id": "18d62e2c",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67eff3c1"
      },
      "source": [
        "## Text pre-processing"
      ],
      "id": "67eff3c1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b55fd032"
      },
      "source": [
        "# function to remove @user\n",
        "def remove_pattern(input_txt, pattern):\n",
        "    r = re.findall(pattern, input_txt)\n",
        "    for i in r:\n",
        "        input_txt = re.sub(i,'',input_txt)\n",
        "    return input_txt"
      ],
      "id": "b55fd032",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6b840fde"
      },
      "source": [
        "# additional cleaning\n",
        "tweets['Tweet'] = np.vectorize(remove_pattern)(tweets['text'], '@[\\w]*') # create new column with removed @user\n",
        "tweets['Tweet'] = tweets['Tweet'].apply(lambda x: re.split('http:\\/\\/.*', str(x))[0]) # remove urls\n",
        "tweets['Tweet'] = tweets['Tweet'].str.replace('[^a-zA-Z#]+',' ') # remove special characters, numbers, punctuations"
      ],
      "id": "6b840fde",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8a692bb"
      },
      "source": [
        "#Creating a function that takes care of all the preprocessing stuff.\n",
        "def preprocess():\n",
        "    tweets['Tweet'] = tweets['Tweet'].str.lower() # Ensuring all words in the Tweet column of training data are lowercased\n",
        "    #Parsing the stop_words.txt file and storing all the words in a list.\n",
        "    stopwords = nltk.corpus.stopwords.words(\"english\")\n",
        "\n",
        "    #Removing all stopwords from all the tweets in training data.\n",
        "    tweets[\"Tweet\"] = tweets[\"Tweet\"].apply(lambda func: ' '.join(sw \n",
        "                                            for sw in func.split() \n",
        "                                            if sw not in stopwords))\n",
        "    #Training Data\n",
        "    tweets['Tweet'] = tweets['Tweet'].str.replace(r'http?://[^\\s<>\"]+|www\\.[^\\s<>\"]+', '') # Removing hyperlinks from all the tweets\n",
        "    tweets['Tweet'] = tweets['Tweet'].str.replace('@[A-Za-z0-9]+', '') # Removing usernames from all the tweets.\n",
        "    tweets['Tweet'] = tweets['Tweet'].str.replace(r'\\B#\\w*[a-zA-Z]+\\w*', '') # Removing hashtags, including the text, from all the tweets\n",
        "    tweets['Tweet'] = tweets['Tweet'].str.replace('\\d+', '') # Removing numbers from all the tweets\n",
        "    special_chars = [\"!\",'\"',\"%\",\"&\",\"amp\",\"'\",\"(\",\")\", \"*\",\"+\",\",\",\"-\",\".\",\"/\",\":\",\";\",\"<\",\"=\",\">\",\"?\",\"[\",\"\\\\\",\"]\",\"^\",\"_\",\"`\",\"{\",\"|\",\"}\",\"~\",\"â€“\",\"@\",\"#\",\"$\"]\n",
        "    for c in special_chars:\n",
        "        tweets['Tweet'] = tweets['Tweet'].str.replace(c,'') # Removing all special characters from all the tweets\n",
        "preprocess()"
      ],
      "id": "b8a692bb",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "c60e6fbe"
      },
      "source": [
        "# create new variable tokenized tweet \n",
        "tokenized_tweet = tweets['Tweet'].apply(lambda x: x.split())\n",
        "# remove stopwords\n",
        "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
        "tokenized_tweet = [w for w in tokenized_tweet if w not in stopwords]"
      ],
      "id": "c60e6fbe",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "584862fc"
      },
      "source": [
        "# join tokens into one sentence\n",
        "for i in range(len(tokenized_tweet)):\n",
        "    tokenized_tweet[i] = ' '.join(tokenized_tweet[i])\n",
        "# change df['Tweet'] to tokenized_tweet\n",
        "tweets['Tweet']  = tokenized_tweet"
      ],
      "id": "584862fc",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81c9c2cb",
        "outputId": "ae10e995-a292-43f3-8198-97ddc25ba2a0"
      },
      "source": [
        "# tweets after cleaning\n",
        "tweets['Tweet']"
      ],
      "id": "81c9c2cb",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       catholic charities provides low cost immigrati...\n",
              "1       rt media focuses negative sells copy lot envir...\n",
              "2       friendly reminder donate portion proceeds take...\n",
              "3       world poorest countries need support face show...\n",
              "4       rt cause close hearts believe one feel alone i...\n",
              "                              ...                        \n",
              "1995    rt pls rt u retweet https co bq peyi ro giveaw...\n",
              "1996    th annual bigelow tea community challenge call...\n",
              "1997    funraising season officially begun learn help ...\n",
              "1998    rt please follow links donate fundraising two ...\n",
              "1999    rt yesterday cake cutting beginning upcoming d...\n",
              "Name: Tweet, Length: 2000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5294ca8d"
      },
      "source": [
        "## Deriving sentiment"
      ],
      "id": "5294ca8d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "4bf3d968"
      },
      "source": [
        "# assign sentiment scores\n",
        "scores = []\n",
        "for tweet in tweets['Tweet']:\n",
        "    score = sia.polarity_scores(tweet)\n",
        "    scores.append(score['compound'])\n",
        "tweets['sentiment_scores'] = scores\n",
        "tweets['sentiment_derived'] = [\"positive\" if w >0 else \"negative\" if w < 0 else \"neutral\" for w in tweets['sentiment_scores']]"
      ],
      "id": "4bf3d968",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e67f2b55",
        "outputId": "070e3376-cf89-4925-b66e-9873aeb3d007"
      },
      "source": [
        "tweets['sentiment_scores']"
      ],
      "id": "e67f2b55",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       0.2732\n",
              "1      -0.1280\n",
              "2       0.4939\n",
              "3      -0.2023\n",
              "4      -0.0772\n",
              "         ...  \n",
              "1995    0.0772\n",
              "1996    0.0772\n",
              "1997    0.8225\n",
              "1998    0.8934\n",
              "1999   -0.1280\n",
              "Name: sentiment_scores, Length: 2000, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "747a725b",
        "outputId": "0850d46e-bea8-439b-f747-ffffbeeea6db"
      },
      "source": [
        "# percent match between assigned and derived sentiment\n",
        "tweets['match'] = (tweets['sentiment_derived']==tweets['Geo_Enabled']).astype(int)\n",
        "tweets[['Geo_Enabled','sentiment_derived','match']]\n",
        "tweets['match'].mean()"
      ],
      "id": "747a725b",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "5b6050db",
        "outputId": "a5581c64-3902-47b7-c855-30c319ad2437"
      },
      "source": [
        "# crosstab of assigned vs derived sentiment\n",
        "pd.crosstab(tweets.Geo_Enabled, tweets.sentiment_derived)"
      ],
      "id": "5b6050db",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>sentiment_derived</th>\n",
              "      <th>negative</th>\n",
              "      <th>neutral</th>\n",
              "      <th>positive</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Geo_Enabled</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>False</th>\n",
              "      <td>215</td>\n",
              "      <td>68</td>\n",
              "      <td>1006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>True</th>\n",
              "      <td>117</td>\n",
              "      <td>61</td>\n",
              "      <td>533</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "sentiment_derived  negative  neutral  positive\n",
              "Geo_Enabled                                   \n",
              "False                   215       68      1006\n",
              "True                    117       61       533"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04NSVDaYLca1",
        "outputId": "37555073-255e-495a-ee4e-ebcf9cea995c"
      },
      "source": [
        "import nltk\n",
        "nltk.download('movie_reviews')\n",
        "nltk.download('punkt')"
      ],
      "id": "04NSVDaYLca1",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10b41d79",
        "outputId": "dc74db37-2215-447b-93be-6465a305a5dc"
      },
      "source": [
        "blobber = Blobber(analyzer=NaiveBayesAnalyzer())\n",
        "\n",
        "blob = TextBlob(\"i love it!\")\n",
        "print(blob.sentiment)\n",
        "\n",
        "blob = blobber(\"i hate it!\")\n",
        "print(blob.sentiment)"
      ],
      "id": "10b41d79",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentiment(polarity=0.625, subjectivity=0.6)\n",
            "Sentiment(classification='pos', p_pos=0.523148148148148, p_neg=0.4768518518518517)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0266634c"
      },
      "source": [
        "scores = []\n",
        "for tweet in tweets['Tweet']:\n",
        "    score = TextBlob(tweet)\n",
        "    scores.append(score.sentiment[0])\n",
        "tweets['textblob_scores'] = scores\n",
        "tweets['textblob_derived'] = [\"positive\" if w >0 else \"negative\" if w < 0 else \"neutral\" for w in tweets['textblob_scores']]"
      ],
      "id": "0266634c",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "40f475fb",
        "outputId": "70a1a2ca-5791-4429-9e3f-b335531685c1"
      },
      "source": [
        "pd.crosstab(tweets.Geo_Enabled, tweets.textblob_derived)\n",
        "pd.crosstab(tweets.sentiment_derived, tweets.textblob_derived)"
      ],
      "id": "40f475fb",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>textblob_derived</th>\n",
              "      <th>negative</th>\n",
              "      <th>neutral</th>\n",
              "      <th>positive</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment_derived</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>negative</th>\n",
              "      <td>158</td>\n",
              "      <td>134</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>11</td>\n",
              "      <td>79</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>173</td>\n",
              "      <td>728</td>\n",
              "      <td>638</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "textblob_derived   negative  neutral  positive\n",
              "sentiment_derived                             \n",
              "negative                158      134        40\n",
              "neutral                  11       79        39\n",
              "positive                173      728       638"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8a6bd2a"
      },
      "source": [
        "# tweets.to_csv('test.csv')"
      ],
      "id": "a8a6bd2a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaec822f"
      },
      "source": [
        "def combined_sentiment(tweets):\n",
        "    if (tweets['textblob_derived'] == 'negative') or (tweets['sentiment_derived'] == 'negative'):\n",
        "        return 'negative'\n",
        "    if (tweets['textblob_derived'] == 'neutral') and (tweets['sentiment_derived'] == 'positive'):\n",
        "        return 'neutral'\n",
        "    if (tweets['textblob_derived'] == 'positive') and (tweets['sentiment_derived'] == 'neutral'):\n",
        "        return 'neutral'\n",
        "    if (tweets['textblob_derived'] == 'neutral') and (tweets['sentiment_derived'] == 'neutral'):\n",
        "        return 'negative'\n",
        "    if (tweets['textblob_derived'] == 'positive') and (tweets['sentiment_derived'] == 'positive'):\n",
        "        return 'positive'\n",
        "    else:\n",
        "        return '0'"
      ],
      "id": "eaec822f",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34a9ccc0"
      },
      "source": [
        "tweets['final_derived'] = tweets.apply(combined_sentiment, axis=1)"
      ],
      "id": "34a9ccc0",
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "5ac9159a",
        "outputId": "69907871-81f9-4eac-b9af-bd060849dbb7"
      },
      "source": [
        "pd.crosstab(tweets.final_derived, tweets.Geo_Enabled)"
      ],
      "id": "5ac9159a",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Geo_Enabled</th>\n",
              "      <th>False</th>\n",
              "      <th>True</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>final_derived</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>negative</th>\n",
              "      <td>373</td>\n",
              "      <td>222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>514</td>\n",
              "      <td>253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>402</td>\n",
              "      <td>236</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Geo_Enabled    False  True \n",
              "final_derived              \n",
              "negative         373    222\n",
              "neutral          514    253\n",
              "positive         402    236"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    }
  ]
}