{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "Twitter Sentiment Analysis final.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROIqTj9_k1RG",
        "outputId": "101af4c1-2b10-4242-b3a8-df30af3eb3ab"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import string\n",
        "import pickle\n",
        "import keras \n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "import gensim\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, Dropout\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import load_model\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaHREn12pOPs",
        "outputId": "4a507bdc-b3ba-475d-ffb7-73583b2c3af6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whVJbk5Hk1RM",
        "outputId": "b4c75b1e-d68a-4119-889a-be5d6a08ea0b"
      },
      "source": [
        "DATASET_COLUMNS = [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\n",
        "DATASET_ENCODING = \"ISO-8859-1\"\n",
        "data = pd.read_csv('/content/drive/MyDrive/training.1600000.processed.noemoticon.csv', encoding =DATASET_ENCODING , names=DATASET_COLUMNS)\n",
        "X = data.iloc[:,[5]]\n",
        "Y = data.iloc[:,0]\n",
        "Y[Y == 4] = 1"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ufADMll3-wu"
      },
      "source": [
        "#**Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9mLGzSGk1RN",
        "outputId": "99ea550a-5c26-4a62-bfd8-f983986083d1"
      },
      "source": [
        "# Text-preprocessing\n",
        "\n",
        "# Missing Values\n",
        "num_missing_desc = data.isnull().sum()[2]    # No. of values with msising descriptions\n",
        "print('Number of missing values: ' + str(num_missing_desc))\n",
        "data = data.dropna()\n",
        "TAG_CLEANING_RE = \"@\\S+\"\n",
        "# Remove @tags\n",
        "X['text'] = X['text'].map(lambda x: re.sub(TAG_CLEANING_RE, ' ', x))\n",
        "# lowercase\n",
        "X['text'] = X['text'].map(lambda x: x.lower())\n",
        "# Remove numbers\n",
        "X['text'] = X['text'].map(lambda x: re.sub(r'\\d+', ' ', x))\n",
        "# Remove links\n",
        "TEXT_CLEANING_RE = \"https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\n",
        "X['text'] = X['text'].map(lambda x: re.sub(TEXT_CLEANING_RE, ' ', x))\n",
        "# Remove Punctuation\n",
        "X['text']  = X['text'].map(lambda x: x.translate(x.maketrans('', '', string.punctuation)))\n",
        "# Remove white spaces\n",
        "X['text'] = X['text'].map(lambda x: x.strip())\n",
        "# Tokenize into words\n",
        "X['text'] = X['text'].map(lambda x: word_tokenize(x))\n",
        "# Remove non alphabetic tokens\n",
        "X['text'] = X['text'].map(lambda x: [word for word in x if word.isalpha()])\n",
        "# Filter out stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "X['text'] = X['text'].map(lambda x: [w for w in x if not w in stop_words])\n",
        "# Word Lemmatization\n",
        "lem = WordNetLemmatizer()\n",
        "X['text'] = X['text'].map(lambda x: [lem.lemmatize(word,\"v\") for word in x])\n",
        "# Turn lists back to string\n",
        "X['text'] = X['text'].map(lambda x: ' '.join(x))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of missing values: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "PLngUwqTk1RO",
        "outputId": "4c974a92-5da4-49db-9c93-7260ad91519c"
      },
      "source": [
        "X.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>zl awww bummer shoulda get david carr third day</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>upset update facebook texting might cry result...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dive many time ball manage save rest go bound</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>whole body feel itchy like fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>behave mad see</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0    zl awww bummer shoulda get david carr third day\n",
              "1  upset update facebook texting might cry result...\n",
              "2      dive many time ball manage save rest go bound\n",
              "3                    whole body feel itchy like fire\n",
              "4                                     behave mad see"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FKLkI81k1RP",
        "outputId": "a6666080-fba3-48fe-cb34-66e65f2f00e1"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "print(\"TRAIN size:\", len(X_train))\n",
        "print(\"TEST size:\", len(y_test))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN size: 1280000\n",
            "TEST size: 320000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9lwnVlo4ETV"
      },
      "source": [
        "#**Create word2vec**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqORfVJbk1RR"
      },
      "source": [
        "# WORD2VEC \n",
        "W2V_SIZE = 300\n",
        "W2V_WINDOW = 7\n",
        "W2V_EPOCH = 32\n",
        "W2V_MIN_COUNT = 10\n",
        "documents = [_text.split() for _text in X_train.text] \n",
        "w2v_model = gensim.models.word2vec.Word2Vec(size=W2V_SIZE, window=W2V_WINDOW, min_count=W2V_MIN_COUNT, workers=8)\n",
        "w2v_model.build_vocab(documents)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eSfu_Dtk1RR",
        "outputId": "3af98799-7500-498a-c203-8cf98ca33864"
      },
      "source": [
        "words = w2v_model.wv.vocab.keys()\n",
        "vocab_size = len(words)\n",
        "print(\"Vocab size\", vocab_size)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size 25276\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qh0Q5RBAk1RS",
        "outputId": "9644ae73-8a65-48e3-c181-654aabb218bb"
      },
      "source": [
        "# Train Word Embeddings\n",
        "w2v_model.train(documents, total_examples=len(documents), epochs=W2V_EPOCH)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(251365039, 289225504)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FN-_mpNt4O87"
      },
      "source": [
        "#**Tokenising and Padding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFi_GEwok1RT",
        "outputId": "d8bf55a4-ad39-43b1-d0ae-7d53e7080e46"
      },
      "source": [
        "# Tokenizing\n",
        "\n",
        "# Max number of words in each complaint.\n",
        "MAX_SEQUENCE_LENGTH = 300\n",
        "# This is fixed.\n",
        "EMBEDDING_DIM = 300\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train.text)\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(word_index)\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "# Convert the data to padded sequences\n",
        "X_train_padded = tokenizer.texts_to_sequences(X_train.text)\n",
        "X_train_padded = pad_sequences(X_train_padded, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "print('Shape of data tensor:', X_train_padded.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 232838 unique tokens.\n",
            "Shape of data tensor: (1280000, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dO1HX9Nik1RU"
      },
      "source": [
        "# saving\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cea6bTSPk1RU",
        "outputId": "b7fbf474-dc10-45f7-85f5-34aa815c0132"
      },
      "source": [
        "# Embedding matrix for the embedding layer\n",
        "embedding_matrix = np.zeros((vocab_size+1, W2V_SIZE))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if word in w2v_model.wv:\n",
        "        embedding_matrix[i] = w2v_model.wv[word]\n",
        "print(embedding_matrix.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(232839, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oYb3r_14WWH"
      },
      "source": [
        "#**Building a Neural Network Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkXkj4iwk1RU",
        "outputId": "de01850f-8ff0-46c5-dd7a-a7c6c40d1d58"
      },
      "source": [
        "# Build Model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size+1, W2V_SIZE, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=False))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()\n",
        "model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 300, 300)          69851700  \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 300, 300)          0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 100)               160400    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 70,012,201\n",
            "Trainable params: 160,501\n",
            "Non-trainable params: 69,851,700\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqOh9ANj4a-q"
      },
      "source": [
        "#**Model Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Q1QbXPrk1RV",
        "outputId": "57f842a2-6a53-41f5-b2a2-19355b6d1b4d"
      },
      "source": [
        "# Training \n",
        "callbacks = [ReduceLROnPlateau(monitor='val_loss', patience=5, cooldown=0), EarlyStopping(monitor='val_accuracy', min_delta=1e-4, patience=5)]\n",
        "history = model.fit(X_train_padded, y_train, batch_size=512, epochs=2, validation_split=0.1, verbose=1, callbacks=callbacks)\n",
        "model.save('main/Sentiment_LSTM_model.h5')\n",
        "with open('main/trainHistoryDict', 'wb') as file_pi:\n",
        "    pickle.dump(history.history, file_pi)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "2250/2250 [==============================] - 1701s 754ms/step - loss: 0.5058 - accuracy: 0.7491 - val_loss: 0.4699 - val_accuracy: 0.7748\n",
            "Epoch 2/2\n",
            "2250/2250 [==============================] - 1696s 754ms/step - loss: 0.4859 - accuracy: 0.7624 - val_loss: 0.4667 - val_accuracy: 0.7773\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrWtAPgvk1RV",
        "outputId": "50f1483f-c2f1-4e87-c3d1-7588bbdbdae4"
      },
      "source": [
        "# Load Model\n",
        "model = load_model('main/Sentiment_LSTM_model.h5')\n",
        "# loading tokenizer\n",
        "with open('main/trainHistoryDict', 'rb') as file_pi:\n",
        "    history = pickle.load(file_pi)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVrqh0KX4ene"
      },
      "source": [
        "#**Model Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcsotOI8k1RW",
        "outputId": "f53429d2-b9ca-48b9-dce8-26503c0f44c7"
      },
      "source": [
        "# Evaluation\n",
        "X_test_padded = tokenizer.texts_to_sequences(X_test.text)\n",
        "X_test_padded = pad_sequences(X_test_padded, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "score = model.evaluate(X_test_padded, y_test, batch_size=512)\n",
        "print(\"ACCURACY:\",score[1])\n",
        "print(\"LOSS:\",score[0])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 108s 173ms/step - loss: 0.4653 - accuracy: 0.7783\n",
            "ACCURACY: 0.7782999873161316\n",
            "LOSS: 0.4652949273586273\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ucllW6y4qsq"
      },
      "source": [
        "#**Test Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IH8bKdfxk1RW"
      },
      "source": [
        "def predict(text, include_neutral=True):\n",
        "    # Tokenize text\n",
        "    x_test = pad_sequences(tokenizer.texts_to_sequences([text]), maxlen=MAX_SEQUENCE_LENGTH)\n",
        "    # Predict\n",
        "    score = model.predict([x_test])[0]\n",
        "    if(score >=0.4 and score<=0.6):\n",
        "        label = \"Neutral\"\n",
        "    if(score <=0.4):\n",
        "        label = \"Negative\"\n",
        "    if(score >=0.6):\n",
        "        label = \"Positive\"\n",
        "\n",
        "    return {\"label\" : label,\n",
        "        \"score\": float(score)}  "
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pchutR42k1RW",
        "outputId": "d4c5e127-51cb-4103-c78c-514a4c5fe780"
      },
      "source": [
        "predict(\"jonasbrothers best buddies chapter needs may talk charity donation silent auction charity best buddies plz follow talk\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 'Positive', 'score': 0.9460958242416382}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}